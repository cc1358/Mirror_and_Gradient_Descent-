The results of this study highlight the performance of Mirror Descent, Adaptive Mirror Descent, Stochastic Mirror Descent, and Gradient Descent in minimizing an L1-regularized objective function over the probability simplex. Mirror Descent achieves an average regret of 0.002914, demonstrating its effectiveness for constrained optimization problems. Adaptive Mirror Descent performs even better, with an average regret of 0.000090, showcasing the benefits of dynamically adjusting step sizes to improve convergence. Stochastic Mirror Descent, which introduces noise to the gradients to simulate real-world uncertainty, achieves an average regret of 0.001117, proving its robustness in noisy environments. Surprisingly, Gradient Descent outperforms the other methods in this specific setup, achieving the lowest average regret of 0.000019, likely due to the simplicity of the problem and the effectiveness of Euclidean projections onto the simplex. The theoretical regret bound at 
T=1000 is 0.093915, which serves as a benchmark for comparing the algorithms' performance. These results illustrate the trade-offs between the algorithms: while Mirror Descent and its variants excel in handling constraints and noise, Gradient Descent can be highly effective in simpler, well-behaved scenarios. This study underscores the importance of choosing the right optimization algorithm based on the problem's structure and constraints.
